# sesgos 

## 1. Alucinación semántica
- Definición: generación de información falsa, imprecisa o inventada con coherencia superficial.
- Riesgo: erosiona la confianza epistémica.


### solución

- Integrar verificadores de fuentes y referencias estructurales.
- Enseñar lectura crítica de outputs generados.


<ref>
Bender, E. M., & Koller, A. (2020). Climbing towards NLU: On meaning, form, and understanding in the age of data. *ACL*.

Marcus, G. (2022). Deep learning is hitting a wall. *MIT Technology Review*.
</ref>

---

## 2. Plagio automático / mimetismo textual
- Definición: reproducción no intencional de contenidos previos sin atribución.
- Riesgo: difumina la autoría, daña la ética académica.

<ref>
Purdy, J. P. (2018). What can automation tell us about agency? *Computers and Composition*, 49, 40–50.
Howard, R. M. (1999). *Standing in the shadow of giants: Plagiarists, authors, collaborators*. Ablex Publishing.
</ref>


Solución:
	- Reforzar enseñanza de parafraseo, síntesis y citación creativa.
	- Promover escritura reflexiva con trazabilidad.

---

## 3. Sesgo de confirmación algorítmico
- Definición: refuerzo automático de creencias del usuario.
- Riesgo: cristaliza burbujas ideológicas.

<ref>
Pariser, E. (2011). *The Filter Bubble: What the Internet Is Hiding from You*. Penguin.
Bozdag, E. (2013). Bias in algorithmic filtering and personalization. *Ethics and Information Technology*, 15(3).
</ref>


Solución:
	- Diseñar prompts que soliciten contraejemplos.
	- Implementar políticas de disenso cognitivo activo en clase.

---

## 4. Estética del consenso superficial
- Definición: generación de textos suaves, neutrales, sin conflicto.
- Riesgo: empobrece el pensamiento crítico.

<ref>
Gunkel, D. J. (2020). An introduction to communication and artificial intelligence. *Polity*.
Lanier, J. (2014). *Who owns the future?* Simon and Schuster.
</ref>


Solución:
	- Evaluar no solo la claridad, sino la densidad argumentativa.
	- Fomentar redacciones que incluyan controversia fundamentada.

---

## 5. Sesgo de sobreinformación no jerárquica
- Definición: exceso de información sin discriminación o jerarquía.
- Riesgo: dispersión cognitiva, falsa exhaustividad.

<ref>
Floridi, L. (2010). Information: A very short introduction. *Oxford University Press*.
Sundar, S. S. (2008). The MAIN model. *Human Communication Research*, 34(3).
</ref>


Solución:
	- Enseñar modelos de jerarquización y curaduría.
	- Pedir síntesis jerarquizadas y análisis comparativos.

---

## 6. Sesgo lingüístico-cultural
- Definición: predominio de valores, lenguaje y epistemes anglófonas.
- Riesgo: invisibilización de tradiciones periféricas.

<ref>
Canagarajah, A. S. (2002). *A geopolitics of academic writing*. University of Pittsburgh Press.
Spivak, G. C. (1988). Can the subaltern speak? *Marxism and the Interpretation of Culture*.
</ref>


Solución:
	- Incluir epistemologías del sur y plurilingüismo en prompts y bibliografía.
	- Traducir desde el contexto, no solo desde el idioma.

---

## 7. Externalización de la agencia cognitiva
- Definición: delegar el pensar, leer y sintetizar en el modelo.
- Riesgo: debilita la agencia formativa del estudiante.

<ref>
Hayles, N. K. (2012). *How we think: Digital media and contemporary technogenesis*. University of Chicago Press.
Stiegler, B. (2010). *Taking Care of Youth and the Generations*. Stanford University Press.
</ref>


Solución:
	- Hacer visible el proceso cognitivo detrás del uso de IA.
	- Solicitar metarreflexiones junto a cada texto generado.

---

## 8. Sesgo de eficiencia productivista
- Definición: prioriza la forma útil sobre el proceso exploratorio.
- Riesgo: destruye la temporalidad lenta de la investigación.

<ref>
Hartmut Rosa (2013). *Social Acceleration: A New Theory of Modernity*. Columbia University Press.
Mountz, A. et al. (2015). Slow scholarship: A feminist politics of resistance. *ACME: An International Journal for Critical Geographies*.
</ref>


Solución:
	- Evaluar la calidad del proceso, no solo el producto.
	- Integrar tareas de deriva conceptual o escritura no resolutiva.

---

## 9. Homogenización metodológica
- Definición: imposición de estructuras académicas convencionales.
- Riesgo: borra metodologías críticas o experimentales.

<ref>
Lather, P. (2007). *Getting Lost: Feminist Efforts toward a Double(d) Science*. SUNY Press.
Trinh T. Minh-ha (1989). *Woman, Native, Other*. Indiana University Press.
</ref>


Solución:
	- Validar experimentación metodológica guiada.
	- Pedir ensayos en formas no estándar: glosas, manifiestos, ficciones teóricas.

---

## 10. Sesgo de autoridad sintética
- Definición: atribución de legitimidad automática al output generado.
- Riesgo: desactiva el juicio crítico.

<ref>
Noble, S. U. (2018). *Algorithms of Oppression: How Search Engines Reinforce Racism*. NYU Press.
Gillespie, T. (2014). The relevance of algorithms. *Media Technologies*.
</ref>


Solución:
	- Exigir siempre trazabilidad de fuentes y justificación del modelo.
	- Enseñar a preguntar “quién habla” detrás de cada output.

---

# desplazamientos 

<img src="https://i.imgur.com/Pf5tdxk.png" style="filter: invert(1);">

1. tareas humanas (negro)
2. máquinas autónomas (blanco, reconfiguración de la agencia humana)
3. nuevas tareas habilitadas por IA.


---
##  tareas humanas 
La parte *blanca* (tareas humanas automatizables) ha sido ampliamente estudiada por la economía del trabajo y la teoría de la automatización. Investigadores como Frey y Osborne (2013) analizaron qué ocupaciones corren más riesgo de automatización, y estudios posteriores (como los del MIT Work of the Future Task Force) introdujeron una visión más matizada: no todos los trabajos desaparecen, sino que las tareas dentro de los trabajos se transforman.

---

## automatización

**La automatización no reemplaza al humano sino que reconfigura su *agencia.***


---


## colaboración humano-máquina.

Aquí se ubica el concepto de inteligencia aumentada, donde la IA no sustituye, sino que potencia las capacidades humanas, permitiendo actividades antes impensables, como:

- Diagnóstico médico asistido por IA (radiología, genómica)
- CAC (Composición asistida por computadoras)
- Diseño paramétrico con herramientas generativas (Midjourney, Runway, etc.)
- Ciencia de datos accesible a no-programadores mediante LLMs
- Invención-construcción de instrumentos? SOOG


---

## solo humanos?

la zona negra delimita (por ahora) a lo exclusicamente humano:

- poesía, narrativa, forma musical
- creatividad radical
-  juicio moral
- cuidado interpersonal
- toma de decisiones en incertidumbre radical. 

---

*Muchos estudios en ética de la IA (**Floridi, Bostrom, Sütfeld**) insisten en que algunas formas de agencia no son reducibles a lógica computacional, aunque sí pueden estar mediadas por ella.*

---

#  referencias

```bibtex
@book{bender2020meaning,
  title={Climbing towards NLU: On meaning, form, and understanding in the age of data},
  author={Bender, Emily M and Koller, Alexander},
  year={2020},
  publisher={ACL}
}

@article{purdy2018agency,
  title={What can automation tell us about agency?},
  author={Purdy, James P.},
  journal={Computers and Composition},
  volume={49},
  pages={40--50},
  year={2018}
}

@book{pariser2011filter,
  title={The Filter Bubble: What the Internet Is Hiding from You},
  author={Pariser, Eli},
  year={2011},
  publisher={Penguin}
}

@book{gunkel2020communication,
  title={An Introduction to Communication and Artificial Intelligence},
  author={Gunkel, David J.},
  year={2020},
  publisher={Polity}
}

@book{floridi2010information,
  title={Information: A very short introduction},
  author={Floridi, Luciano},
  year={2010},
  publisher={Oxford University Press}
}

@book{canagarajah2002geopolitics,
  title={A geopolitics of academic writing},
  author={Canagarajah, A. S.},
  year={2002},
  publisher={University of Pittsburgh Press}
}

@book{hayles2012how,
  title={How we think: Digital media and contemporary technogenesis},
  author={Hayles, N. Katherine},
  year={2012},
  publisher={University of Chicago Press}
}

@book{rosa2013acceleration,
  title={Social Acceleration: A New Theory of Modernity},
  author={Rosa, Hartmut},
  year={2013},
  publisher={Columbia University Press}
}

@book{lather2007getting,
  title={Getting Lost: Feminist Efforts toward a Double(d) Science},
  author={Lather, Patti},
  year={2007},
  publisher={SUNY Press}
}

@book{noble2018algorithms,
  title={Algorithms of Oppression: How Search Engines Reinforce Racism},
  author={Noble, Safiya Umoja},
  year={2018},
  publisher={NYU Press}
}
```


---



## Consideraciones Éticas y Académicas

1. **Integridad académica:** Utiliza estos modelos como herramientas de apoyo, no para sustituir el pensamiento crítico o el trabajo original.
2. **Citación adecuada:** Menciona el uso de IA en tus trabajos según las políticas de tu institución.
3. **Verificación de información:** Contrasta siempre las respuestas con fuentes académicas confiables.
4. **Privacidad de datos:** Evita compartir información personal o datos sensibles en tus prompts.
5. **Sostenibilidad:** Considera el impacto ambiental del uso intensivo de modelos de IA (huella de carbono).



